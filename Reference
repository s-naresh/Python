# Python

durgasoft for hadoop

# C:\Users\nshirsat\AppData\Local\Programs\Python\Python36\Scripts
# path of python interpreter   C:\Users\nshirsat\AppData\Local\Programs\Python\Python36			
  
  
-- pip path
C:\Users\nshirsat\AppData\Local\Continuum\Anaconda3\Scripts

# %LocalAppData%\Programs - paste in windows search

# EDA - pandas_profiling
http://nbviewer.jupyter.org/github/JosPolfliet/pandas-profiling/blob/master/examples/meteorites.ipynb

# comparison R vs Python (pandas)
https://pandas.pydata.org/pandas-docs/stable/comparison_with_r.html

# fast ai - http://www.fast.ai/2018/09/26/ml-launch/

# Python - ML and Mathematics all in one place (Homemade Machine Learning)
https://github.com/trekhleb/homemade-machine-learning

# python learning video like sentdex
http://coreyms.com/

# Bayesian LR in python
https://github.com/WillKoehrsen/Data-Analysis/blob/master/bayesian_lr/Bayesian%20Linear%20Regression%20Project.ipynb

# dan bader
# Oython a to z
https://www.kaggle.com/dark4user/python-programming-from-a-to-z




## library / packages in python
- NLTK = used for Natural language proecessing, sentiment analysis
- requests and BeautifulSoup - used to scrape reviews from websites
- Scikit-learn = is a free software machine learning library for the Python
- Mlpy = is a Python machine learning library built on top of NumPy/SciPy, the GNU Scientific Library.
- Numpy = Mathematical operations , make easy to work with large multidimensional arrays and matrices
- Scipy = SciPy has modules for optimization, linear algebra, integration ,  N-dimensional array manipulation.
- Matplotlib = is a Python module for visualization, graphs
- Python = Used for data manupulation, contains high-level data structures and tools designed for fast and easy data analysis operations.
- Theano = used for numerical computation, and is similar to Numpy. Some libraries such as Pylearn2 use Theano as their core component 
          for mathematical computation. Theano allows you to define, optimize, and evaluate mathematical expressions involving multi-dimensional arrays efficiently.
- Statsmodels = is a Python module that allows users to explore data, estimate statistical models, 
              and perform statistical tests. An extensive list of descriptive statistics, statistical tests, 
			  plotting functions, and result statistics are available for different types of data and each estimator.
			  Time series forecasting
- PyFlux 	= time series forecasting 
- PyBrain = is an acronym for “Python-Based Reinforcement Learning, Artificial Intelligence, and Neural Network”. 
			It is an open source library mainly used for neural networks, reinforcement learning and unsupervised learning.
- Gensim = is a Python library for topic modeling. It is built on Numpy and Scipy.
- Keras = is an open-source library for building Neural Networks at a high-level of the interface 
- Tensorflow = Used to develop deep learning Network 

- Caffe = very useful machine learning library when used for computer vision.
- SHAP (SHapely Additive exPlanation)  = shap used to explain the influence of each feature on model.

- Catboost / XGBoost - gradient boosting

- Facets = Data visualization 
(When visualizing a large amount of data in Dive in a Juypter notebook, as is done in the Dive demo Jupyter notebook, you will need to start the notebook server with an increased IOPub data rate. This can be done with the command jupyter notebook --NotebookApp.iopub_data_rate_limit=10000000)

# NLP packages
- Flashtext
- textstat
- fuzzywuzzy
- pyLDAvis
- spacy
- textblob

# Productinization of models 
- Papermill is an nteract library built for configurable and reliable execution of notebooks with production ecosystems in mind. What Papermill does is rather simple. It take a notebook path and some parameter inputs, then executes the requested notebook with the rendered input. As each cell executes, it saves the resulting artifact to an isolated output notebook.

- Reuter_50_50 Data set

# Links for reference - 
- banking transactions data for exploratory analysis - Dataset from PKDD'99 Discovery Challenge:
https://github.com/justinng1/berka/blob/master/exploration.ipynb


# Packages or libraries installation
- conda install spacy
- pip install spacy
- conda install -c conda-forge spacy

# install
conda install -c conda-forge python-levenshtein


# import csv file using pandas
csv_att = pd.read_csv("D:\FC_docs\FI Marketshare match\CSV_ATTRIBUTES_ACTIVE.csv", low_memory=False)

# type of dataset , dataset type
type(csv_att)

# convert data in to pandas dataframe
pd.DataFrame(df)

# Descriptive stats , summary
df.describe(include='all')
df.describe().transpose()

import pandas_profiling
pandas_profiling.ProfileReport(df)

# delete row \ remove row containing numeric values in strings from pandas dataframe
df[~df.text.str.contains(r'[0-9]')]

# replace non digit and decimals in column
df['sales'].replace(r'[^0-9.]', '', regex=True)

# remove list of characters 
#OF, BANK, CREDIT UNION, CU,FCU, NATIONAL ASSOCIATION, CREDIT CARD, 
vals_to_replace = {'OF':'', 'STATE':'', 'High':''}
df['a'] = df['a'].map(vals_to_replace)

# meaning of [:] , can be apply to list
del arr[:]  # Deletes all the elements in the array

# Insert the correct syntax to add a placeholder for the age parameter.
age = 36
txt = "My name is John, and I am {}"
print(txt.format(age))


# another way
l = ['\d+', '[^\x00-\x80]+', 'ounces', 'ounce', 'tablespoons', 
     'tablespoon', 'teaspoons', 'teaspoon', 'cup', 'cups']
df.ingredient.str.replace('|'.join(l), '', regex=True).str.strip()


# Need to apply the same mapping to multiple columns at once? Use "applymap"

# to know the count of missing 
df.isna().sum().sum() 	   - total missing count in the data
df.isna().sum()		   - total missing count by variable

# find out rows which is missing in dataframe
null_data = df[df.isnull().any(axis=1)]


# to split items in row as to create one row for each item 
df.explode("col_having_listdata")

# Want to combine the small categories in a Series (<10% frequency) into a single category?
1. Save the normalized value counts
2. Filter by frequency & save the index
3. Replace small categories with "Other" 


# Are you scraping webpage using read.html() but it returns too many tables..?
Use the 'match' parameter to find table that contains particular string 

# Three useful ways to convert one set of values to another:
1. map() using a dictionary
2. factorize() to encode each value as an integer
3. comparison statement to return boolean values

# remove Unnamed: 0 , extra column , unwanted
pd.read_csv('file.csv', index_col=0)


# without loop apply transformations to every item (sentence) using built in map function
cleaned = list( map(fun_name, text_data))
cleaned

# memeory usage
import sys

# These are the usual ipython objects, including this one you are creating
ipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']

# Get a sorted list of the objects and their sizes
sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)

# lambda function
	lambda <args> : <return Value> if <condition > ( <return value > if <condition> else <return value>)


# Save model, load model, use for predict.
# Pickle is one method to save models and later use it for prediction. It is used for serializing 
and de-serializing a Python object structure. Any object in python can be pickled so that it can be saved on disk.
# import KNeighborsClassifier model 
from sklearn.neighbors import KNeighborsClassifier as KNN 
knn = KNN(n_neighbors = 3) 
# train model 
knn.fit(X_train, y_train) 
import pickle
# Save the trained model as a pickle string.
save_classifier = open("knn.pickle","wb")
pickle.dump(knn, save_classifier)
save_classifier.close()
# Load the pickled model
classifier_f = open("knn.pickle", "rb")
classifier = pickle.load(classifier_f)
classifier_f.close()
# Use the loaded pickled model to make predictions
classifier.predict(X_test)


# For writing tuple for a single value, you need to include a comma, even though there is a single value. Also at the end you need to write semi-coma as shown below.
# Python has tuple assignment feature which enables you to assign more than one variable at a time. 
# Use {} and .format(var name) to use predefined variable in python comment

-- Advantages of tuple over list
# Iterating through tuple is faster than with list, since tuples are immutable.
# Tuples that consist of immutable elements can be used as key for dictionary, which is not possible with list
# If you have data that is immutable, implementing it as tuple will guarantee that it remains write-protected

-- Dictionaries in a programming language is a type of data-structure used to store information connected in someway. 
Python Dictionary are defined into two elements Keys and Values. Dictionaries do not store their information in any particular order, 
so you may not get your information back in the same order you entered it.

-- Use 'in' or 'not in'operator with if else to find out if particular element present in the system or not 
# Use the "in" operator in code with if statement to check the value of x existing in the list and print the result accordingly
# Use the "not in" operator in code with if statement to check the value of y exist in the list and print the result accordingly
# Operator is: It returns true if two variables point the same object and false otherwise
# Operator is not: It returns false if two variables point the same object and true otherwise


-- Python Questions 
# What is use of "!" in expression print(id + "!")
# if __name__ == '__main__':


## Libararies use
# requests 
     - Requests is used to retrive and load the data from API server (API is a server that you can use to retrieve and send data to using code.)
     - requests.get("url") used to get the information
     - JSON is a way to encode data structures that ensures that they are easily readable by machines. 
     - json.dumps() =  Takes Python object, and converts (dumps) it to a string
     - json.load() = Takes JSON string, and converts(loads) it to a python object
     - params = used to send parameters(optional) 
     
